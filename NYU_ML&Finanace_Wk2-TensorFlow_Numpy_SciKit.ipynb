{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note this is an exercise for NYU Machine Learning & Finance Course offered by Coursera\n",
    "# The focus of this is exercise is Liner Regression and calculating Beta hat coefficients\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "except: pass\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers import core as core_layers\n",
    "try:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    \"\"\"\n",
    "    Utility function to reset current tensorflow computation graph\n",
    "    and set the random seed \n",
    "    \"\"\"\n",
    "    # to make results reproducible across runs\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 3), (7500, 1))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_data(n_points=10000, n_features=3, use_nonlinear=True, \n",
    "                    noise_std=0.1, train_test_split = 4):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    n_points - number of data points to generate\n",
    "    n_features - a positive integer - number of features\n",
    "    use_nonlinear - if True, generate non-linear data\n",
    "    train_test_split - an integer - what portion of data to use for testing\n",
    "    \n",
    "    Return:\n",
    "    X_train, Y_train, X_test, Y_test, n_train, n_features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Linear data or non-linear data?\n",
    "    if use_nonlinear:\n",
    "        weights = np.array([[1.0, 0.5, 0.2],[0.5, 0.3, 0.15]])\n",
    "    else:\n",
    "        weights = np.array([1.0, 0.5, 0.2])\n",
    "        \n",
    "    bias = np.ones(n_points).reshape((-1,1))\n",
    "    low = - np.ones((n_points,n_features),'float')\n",
    "    high = np.ones((n_points,n_features),'float')\n",
    "    \n",
    "    X = np.random.uniform(low=low, high=high)\n",
    "    noise = np.random.normal(size=(n_points, 1))\n",
    "    noise_std = 0.1\n",
    "    \n",
    "    if use_nonlinear:\n",
    "        Y = (weights[0,0] * bias + np.dot(X, weights[0, :]).reshape((-1,1)) + \n",
    "             np.dot(X*X, weights[1, :]).reshape([-1,1]) +\n",
    "             noise_std * noise)\n",
    "    else:\n",
    "        Y = (weights[0] * bias + np.dot(X, weights[:]).reshape((-1,1)) + \n",
    "             noise_std * noise)\n",
    "    \n",
    "    n_test = int(n_points/train_test_split)\n",
    "    n_train = n_points - n_test\n",
    "    \n",
    "    X_train = X[:n_train,:]\n",
    "    Y_train = Y[:n_train].reshape((-1,1))\n",
    "\n",
    "    X_test = X[n_train:,:]\n",
    "    Y_test = Y[n_train:].reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, n_train, n_features\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, n_train, n_features = generate_data(use_nonlinear=False)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.55555302,  0.47756895,  0.41859018],\n",
       "       [ 1.        , -0.50615891,  0.8759816 ,  0.15791025],\n",
       "       [ 1.        ,  0.83423482, -0.89113633, -0.69812078],\n",
       "       ..., \n",
       "       [ 1.        , -0.07199804, -0.26047484,  0.94713899],\n",
       "       [ 1.        , -0.96814736,  0.52420104, -0.83776189],\n",
       "       [ 1.        , -0.46006237,  0.36096295, -0.55180372]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "#X = np.c_[ X_train, np.ones(X_train.shape[0])]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def numpy_lin_regress(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    numpy_lin_regress - Implements linear regression model using numpy module\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    # number of features\n",
    "    ndim = X_train.shape[1] \n",
    "    X = np.c_[np.ones(X_train.shape[0]), X_train] \n",
    "    #X = np.c_[X_train, np.ones(X_train.shape[0])] \n",
    "    theta_numpy = np.linalg.lstsq(X,Y_train)[0]\n",
    "    \n",
    "    return theta_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "theta_numpy = numpy_lin_regress(X_train, Y_train)\n",
    "theta_numpy.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def sklearn_lin_regress(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    ndim = X_train.shape[1] \n",
    "   \n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train,Y_train)\n",
    "    \n",
    "    theta_sklearn = np.append(lm.intercept_, lm.coef_)\n",
    "    \n",
    "    return theta_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "theta_sklearn = sklearn_lin_regress(X_train, Y_train)\n",
    "theta_sklearn.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression with Tensorflow\n",
    "# A gentle introduction to TensorFlow\n",
    "\n",
    "def tf_lin_regress(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    ndim = X_train.shape[1] \n",
    "    ### START CODE HERE ### (≈ 7-8 lines of code)\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, ndim], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 1], name = \"Y\")\n",
    "    \n",
    "    # Regression parameter using the normal equation\n",
    "    theta_in = tf.placeholder(tf.float32, [ndim + 1, None])\n",
    "    \n",
    "    data_plus_bias = tf.concat([tf.ones([tf.shape(X)[0], 1]), X], axis =1)\n",
    "\n",
    "    XT = tf.transpose(data_plus_bias)\n",
    "    \n",
    "    theta_value = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, data_plus_bias)), XT), Y)\n",
    "    \n",
    "    # Start a session to be able to run operations\n",
    "    \n",
    "    with tf.Session() as sess: \n",
    "        result = sess.run(theta_value,feed_dict={X: X_train, Y: Y_train})\n",
    "        #print(result)\n",
    "    sess.close()\n",
    "    \n",
    "    #print(result)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Beta_hat using TensorFlow:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99953949,  1.00239229,  0.50159907,  0.20129436], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Linear Regression Beta_hat using TensorFlow:\")\n",
    "print()\n",
    "theta_tf = tf_lin_regress(X_train, Y_train)\n",
    "theta_tf.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Beta_hat using SciKit Learn:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression Beta_hat using SciKit Learn:\")\n",
    "print()\n",
    "theta_sklearn = sklearn_lin_regress(X_train, Y_train)\n",
    "theta_sklearn.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Beta_hat using NumPy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression Beta_hat using NumPy:\")\n",
    "print()\n",
    "theta_numpy = numpy_lin_regress(X_train, Y_train)\n",
    "theta_numpy.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_normal_eq(X_train, Y_train, X_test, Y_test, learning_rate=0.05):\n",
    "    \"\"\"\n",
    "    Implements normal equation using tensorflow, trains the model using training data set\n",
    "    Tests the model quality by computing mean square error (MSE) of the test data set\n",
    "    \n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    X_test  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_test - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    \n",
    "    Return a tuple of:\n",
    "        - np.array of size (k+1 by 1) of regression coefficients\n",
    "        - mean square error (MSE) of the test data set\n",
    "        - mean square error (MSE) of the training data set\n",
    "    \"\"\"\n",
    "    ndim_train = X_train.shape[1]\n",
    "    ndim_test = X_test.shape[1]\n",
    "    \n",
    "    X_tr = tf.placeholder(tf.float32, [None, ndim_train], name = \"X_tr\")\n",
    "    Y_tr = tf.placeholder(tf.float32, [None, 1], name = \"Y_tr\")\n",
    "    \n",
    "    X_tst = tf.placeholder(tf.float32, [None, ndim_test], name = \"X_tst\")\n",
    "    Y_tst = tf.placeholder(tf.float32, [None, 1], name = \"Y_tst\")\n",
    "    \n",
    "    data_plus_bias_train = tf.concat([tf.ones([tf.shape(X_tr)[0], 1]), X_tr], axis =1)\n",
    "    data_plus_bias_test = tf.concat([tf.ones([tf.shape(X_tst)[0], 1]), X_tst], axis =1)\n",
    "    \n",
    "    lr_mse_train = 0.\n",
    "    lr_mse_test = 0.\n",
    "    \n",
    "    \n",
    "    XT = tf.transpose(data_plus_bias_train)\n",
    "    \n",
    "    theta_value = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, data_plus_bias_train)), XT), Y_tr)\n",
    "    \n",
    "    lr_mse_train = tf.reduce_mean(tf.square(tf.matmul(data_plus_bias_train, theta_value) - Y_tr))\n",
    "    lr_mse_test = tf.reduce_mean(tf.square(tf.matmul(data_plus_bias_test, theta_value) - Y_tst))\n",
    "    \n",
    "    # Start a session to be able to run operations\n",
    "    \n",
    "    with tf.Session() as sess: \n",
    "        result, lr_mse_train, lr_mse_test = sess.run([theta_value,lr_mse_train,lr_mse_test],\\\n",
    "                                                          feed_dict={X_tr: X_train, Y_tr: Y_train, X_tst: X_test, Y_tst: Y_test})\n",
    "        print(\"Linear Regression Mean Squared Error for Training Data:\")\n",
    "        print(lr_mse_train)\n",
    "        print()\n",
    "        print(\"Linear Regression Mean Squared Error for Test Data:\")\n",
    "        print(lr_mse_test)\n",
    "        print()\n",
    "        \n",
    "    sess.close()\n",
    "    \n",
    "   \n",
    "    return result, lr_mse_train, lr_mse_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error for Training Data:\n",
      "0.00977294\n",
      "\n",
      "Linear Regression Mean Squared Error for Test Data:\n",
      "0.0103219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta_value, lr_mse_train, lr_mse_test = run_normal_eq(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99953949,  1.00239229,  0.50159907,  0.20129436], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "theta_value.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Beta_hat using NumPy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression Beta_hat using NumPy:\")\n",
    "print()\n",
    "theta_numpy = numpy_lin_regress(X_train, Y_train)\n",
    "theta_numpy.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "Y_Train_pred = lm.predict(X_train)\n",
    "Y_Test_pred = lm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_train = mean_squared_error(Y_train, Y_Train_pred)\n",
    "mse_test = mean_squared_error(Y_test, Y_Test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SciKit Learn:\n",
      "Linear Regression Mean Square Error for Training Data:\n",
      "0.00977294340974\n",
      "\n",
      "Linear Regression Mean Square Error for Test Data:\n",
      "0.0103219324219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using SciKit Learn:\")\n",
    "print(\"Linear Regression Mean Square Error for Training Data:\")\n",
    "print(mse_train)\n",
    "print()\n",
    "print(\"Linear Regression Mean Square Error for Test Data:\")\n",
    "print(mse_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow:\n",
      "Linear Regression Mean Squared Error for Training Data:\n",
      "0.00977294\n",
      "\n",
      "Linear Regression Mean Squared Error for Test Data:\n",
      "0.0103219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using TensorFlow:\")\n",
    "theta_value, lr_mse_train, lr_mse_test = run_normal_eq(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def numpy_lin_reg(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    numpy_lin_regress - Implements linear regression model using numpy module\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    # Note: This function calculates the Beta hat coefficients by explictiy using the\n",
    "    # normal equation: w(Beta hat) =(XTX)−1*XT*Y\n",
    "    # number of features\n",
    "    ndim = X_train.shape[1] \n",
    "    X = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "    X_T = np.transpose(X)\n",
    "    ralph = np.linalg.inv(np.dot(X_T,X))\n",
    "    selina = np.dot(X_T,Y_train)\n",
    "    # theta_numpy is Beta hat coefficients\n",
    "    theta_numpy = np.dot(ralph,selina)\n",
    "\n",
    "    return theta_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Beta_hat using NumPy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression Beta_hat using NumPy:\")\n",
    "print()\n",
    "theta_numpy = numpy_lin_regress(X_train, Y_train)\n",
    "theta_numpy.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Beta_hat using NumPy version 2:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression Beta_hat using NumPy version 2:\")\n",
    "print()\n",
    "theta_numpy_2 = numpy_lin_reg(X_train, Y_train)\n",
    "theta_numpy_2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Beta_hat using SciKit Learn:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99953953,  1.00239293,  0.50159933,  0.20129424])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Linear Regression Beta_hat using SciKit Learn:\")\n",
    "print()\n",
    "theta_sklearn = sklearn_lin_regress(X_train, Y_train)\n",
    "theta_sklearn.squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
